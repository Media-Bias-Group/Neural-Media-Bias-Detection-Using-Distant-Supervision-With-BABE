{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this script, you need the following files found in the /data directory:\n",
    "- \"final_labels_SG1.xlsx\"\n",
    "- \"final_labels_SG2.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4kqNVQx-pD4"
   },
   "source": [
    "## Imports and set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10170,
     "status": "ok",
     "timestamp": 1620807725268,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "92Q3zPSjalf0",
    "outputId": "7e49e098-6a0a-4610-a2db-ac228510ac44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 9.1MB/s \n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 33.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 46.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 8.0MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.95\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1460,
     "status": "ok",
     "timestamp": 1620807730492,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "9d2EFrDIUXUG",
    "outputId": "3892b8b3-d418-4bc1-beaa-2d2d869a2b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 12 08:22:09 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26553,
     "status": "ok",
     "timestamp": 1620807760914,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "667g0q9jYX8D",
    "outputId": "7a26b416-bb27-4bd0-b375-d54d5f8b5018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from typing import Dict, List, Optional, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, BertConfig, TFBertForSequenceClassification\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
    "from transformers import ElectraTokenizer, TFElectraForSequenceClassification\n",
    "from transformers import XLNetTokenizer, TFXLNetForSequenceClassification\n",
    "from transformers import LongformerTokenizer, TFLongformerForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1620807761508,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "abdzY7ARYX8M"
   },
   "outputs": [],
   "source": [
    "# set seed, TF uses python ramdom and numpy library, so these must also be fixed\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "os.environ['PYTHONHASHSEED']=str(0)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2146,
     "status": "ok",
     "timestamp": 1620807763097,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "DkbVcSRQppUw",
    "outputId": "c12cff5d-911f-4a71-cf14-0068ca0ee54f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if hardware accelerator available\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 6078,
     "status": "ok",
     "timestamp": 1620807767043,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "Pboq8uWHq2oe",
    "outputId": "c4c0bdcf-f0ea-41f6-cc75-428543d96641"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlNn9cexsKPx"
   },
   "source": [
    "If GPUs are available, tensorflow will give priority to it automatically and computations will be performed on the GPU as default. That behavior can be changed by assigning a task explicitly to a device. Example:\n",
    "\n",
    "```\n",
    "with tf.device('/CPU:0'):\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-sm3aAxZr5R"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1620809519238,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "k3AlX8qqroZE",
    "outputId": "64de8fc8-ec64-4e7b-8caf-78bbd1c85a5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>news_link</th>\n",
       "      <th>outlet</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>Label_bias</th>\n",
       "      <th>label_opinion</th>\n",
       "      <th>biased_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YouTube is making clear there will be no “birt...</td>\n",
       "      <td>https://eu.usatoday.com/story/tech/2020/02/03/...</td>\n",
       "      <td>usa-today</td>\n",
       "      <td>elections-2020</td>\n",
       "      <td>center</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The increasingly bitter dispute between Americ...</td>\n",
       "      <td>https://www.nbcnews.com/news/sports/women-s-te...</td>\n",
       "      <td>msnbc</td>\n",
       "      <td>sport</td>\n",
       "      <td>left</td>\n",
       "      <td>No agreement</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So while there may be a humanitarian crisis dr...</td>\n",
       "      <td>https://www.alternet.org/2019/01/here-are-5-of...</td>\n",
       "      <td>alternet</td>\n",
       "      <td>immigration</td>\n",
       "      <td>left</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A professor who teaches climate change classes...</td>\n",
       "      <td>https://www.breitbart.com/politics/2019/05/09/...</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>environment</td>\n",
       "      <td>right</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking around the United States, there is nev...</td>\n",
       "      <td>https://thefederalist.com/2020/03/11/woman-who...</td>\n",
       "      <td>federalist</td>\n",
       "      <td>abortion</td>\n",
       "      <td>right</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  ... biased_words\n",
       "0  YouTube is making clear there will be no “birt...  ...           []\n",
       "1  The increasingly bitter dispute between Americ...  ...           []\n",
       "2  So while there may be a humanitarian crisis dr...  ...           []\n",
       "3  A professor who teaches climate change classes...  ...           []\n",
       "4  Looking around the United States, there is nev...  ...           []\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_sg1 = \"data/final_labels_SG1.xlsx\"\n",
    "PATH_sg2 = \"data/final_labels_SG2.xlsx\"\n",
    "df_sg1 = pd.read_excel(PATH_sg1)\n",
    "df_sg2 = pd.read_excel(PATH_sg2)\n",
    "df_sg1.rename(columns={'text': 'sentence', 'label_bias': 'Label_bias'}, inplace=True)\n",
    "df_sg2.rename(columns={'text': 'sentence', 'label_bias': 'Label_bias'}, inplace=True)\n",
    "df_sg1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1620809522122,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "8v7O9nyvYX8P"
   },
   "outputs": [],
   "source": [
    "# binarize classification problem\n",
    "df_sg1 = df_sg1[df_sg1['Label_bias']!='No agreement']\n",
    "df_sg1 = df_sg1[df_sg1['Label_bias'].isna()==False]\n",
    "df_sg1.replace(to_replace='Biased', value=1, inplace=True)\n",
    "df_sg1.replace(to_replace='Non-biased', value=0, inplace=True)\n",
    "\n",
    "df_sg2 = df_sg2[df_sg2['Label_bias']!='No agreement']\n",
    "df_sg2.replace(to_replace='Biased', value=1, inplace=True)\n",
    "df_sg2.replace(to_replace='Non-biased', value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 804,
     "status": "ok",
     "timestamp": 1620808980811,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "pRzJDtTif2iH"
   },
   "outputs": [],
   "source": [
    "# Stratified k-Fold instance\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzQYIT1wCG-m"
   },
   "source": [
    "The rest of the preprocessing needs to be performed inside the folds as a) encoder layers shouldn't be allowed to see whole data to construct the lookups and b) indexing with skfold is not possible when data is in tensorflow format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 479,
     "status": "ok",
     "timestamp": 1620809093995,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "hXTxU-BNYX8P"
   },
   "outputs": [],
   "source": [
    "# helper functions called in skfold loop\n",
    "\n",
    "def pd_to_tf(df):\n",
    "    \"\"\"convert a pandas dataframe into a tensorflow dataset\"\"\"\n",
    "    target = df.pop('Label_bias')\n",
    "    sentence = df.pop('sentence')\n",
    "    return tf.data.Dataset.from_tensor_slices((sentence.values, target.values))\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])\n",
    "  plt.show()\n",
    "\n",
    "def tokenize(df):\n",
    "    \"\"\"convert a pandas dataframe into a tensorflow dataset and run hugging face's tokenizer on data\"\"\"\n",
    "    target = df.pop('Label_bias')\n",
    "    sentence = df.pop('sentence')\n",
    "\n",
    "    train_encodings = tokenizer(\n",
    "                        sentence.tolist(),                      \n",
    "                        add_special_tokens = True, # add [CLS], [SEP]\n",
    "                        truncation = True, # cut off at max length of the text that can go to BERT\n",
    "                        padding = True, # add [PAD] tokens\n",
    "                        return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
    "              )\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(train_encodings), \n",
    "         target.tolist()))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUMxPAGdYX8W"
   },
   "source": [
    "## Attention-based models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163,
     "referenced_widgets": [
      "81dd8afd3da148c084f84b3d34329812",
      "fc5f1f66fc694d668251a47e1e379f8b",
      "1ff2fa37c94e412c836224c447fe6bf7",
      "bfaab7f593fb4bd088a64592a8b53663",
      "d632b1a86e4e4492b99cf549e3f021ec",
      "c9f8a2524f8a4c17a197a8078e31ce49",
      "46ce1f04fe3140f5962fa05c7cc71f28",
      "5c3ba5b9183d4fe697e84337907920b8",
      "6c52cabb9ece48b58ceb073437fdc439",
      "e46833e1a05e48ae8b1c6087bb00ee0f",
      "23855aa0fb6244d98d5044da23814836",
      "dbeee3b64dc94284a4775f2a0cb4dfa4",
      "c2f751936f5746ae939295cb88367292",
      "d3245d896e7c4f158ab0b4da76ea93a4",
      "3b6867a6625c4f9890040cabfc57f3a7",
      "caceb8515d614c109d4f74848530aa51",
      "79df1255843b48aabe25b5ff547b5783",
      "d19186b71be744899b772642934539e1",
      "bafa4dd539714c5b8100494b9b5bf071",
      "553ed5546d45464db8cfa1c67fee040a",
      "ca24677e1d2f4431a14c60ba268bf0fb",
      "81e01b1fc1824ae6a795c324f05d43f7",
      "d499b2c8dc88467ca3fb077c364163cf",
      "311c872733504f0a804f73f6f49a9ea4"
     ]
    },
    "executionInfo": {
     "elapsed": 3002,
     "status": "ok",
     "timestamp": 1620809353803,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "QIIWDGdwTZap",
    "outputId": "6d87f2cf-43a0-4c6b-d872-cc60bb07ac60"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dd8afd3da148c084f84b3d34329812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c52cabb9ece48b58ceb073437fdc439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79df1255843b48aabe25b5ff547b5783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def run_model_5fold(df_train, model_name, freeze_encoder=True, pretrained=False, plot=False):\n",
    "  \"\"\"\"freeze flags whether encoder layer should be frozen to not destroy transfer learning. Only set to false when enough data is provided\"\"\"\n",
    "\n",
    "  # these variables will be needed for skfold to select indices\n",
    "  Y = df_train['Label_bias']\n",
    "  X = df_train['sentence']\n",
    "\n",
    "  # hyperparams\n",
    "  BUFFER_SIZE = 10000\n",
    "  BATCH_SIZE = 32\n",
    "  k = 1\n",
    "\n",
    "  val_loss = []\n",
    "  val_acc = []\n",
    "  val_prec = []\n",
    "  val_rec = []\n",
    "  val_f1 = []\n",
    "  val_f1_micro = []\n",
    "  val_f1_wmacro = []\n",
    "\n",
    "  for train_index, val_index in skfold.split(X,Y):\n",
    "    print('### Start fold {}'.format(k))\n",
    "    \n",
    "    # split into train and validation set\n",
    "    train_dataset = df_train.iloc[train_index]\n",
    "    val_dataset = df_train.iloc[val_index]\n",
    "\n",
    "    # prepare data for transformer\n",
    "    train_dataset = tokenize(train_dataset)\n",
    "    val_dataset = tokenize(val_dataset)\n",
    "\n",
    "    # mini-batch it\n",
    "    train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # create new model\n",
    "    if model_name == 'bert':\n",
    "      model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "    if model_name == 'distilbert':\n",
    "      model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "    elif model_name == 'roberta':\n",
    "      model = TFRobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "    elif model_name == 'electra':\n",
    "      model = TFElectraForSequenceClassification.from_pretrained('google/electra-small-discriminator')\n",
    "    elif model_name == 'xlnet':\n",
    "      model = TFXLNetForSequenceClassification.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "\n",
    "    if freeze_encoder == True:\n",
    "      for w in model.get_layer(index=0).weights:\n",
    "        w._trainable = False\n",
    "\n",
    "    # compile it\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5) \n",
    "    model.compile(optimizer=optimizer, loss=model.compute_loss) \n",
    "\n",
    "    # transfer learning\n",
    "    if pretrained == True:\n",
    "      model.get_layer(index=0).set_weights(trained_model_layer) # load bias-specific weights\n",
    "      #model.load_weights('./checkpoints/')\n",
    "    \n",
    "    # after 2 epochs without improvement, stop training\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\n",
    "\n",
    "    # fit it\n",
    "    history = model.fit(train_dataset, epochs=10, validation_data = val_dataset, callbacks=[callback])\n",
    "    \n",
    "    # plot history\n",
    "    if plot:\n",
    "      plot_graphs(history,'loss')\n",
    "\n",
    "    # evaluate\n",
    "    loss = model.evaluate(val_dataset)\n",
    "    \n",
    "    if model_name == 'xlnet':\n",
    "      yhats = []\n",
    "      for row in df_train.iloc[val_index]['sentence']:\n",
    "        input = tokenizer(row, return_tensors=\"tf\")\n",
    "        output = model(input)\n",
    "        logits = output.logits.numpy()[0]\n",
    "        candidates = logits.tolist()\n",
    "        decision = candidates.index(max(candidates))\n",
    "        yhats.append(decision)\n",
    "    else:\n",
    "      logits = model.predict(val_dataset)  \n",
    "      yhats = []\n",
    "      for i in logits[0]:\n",
    "        # assign class label according to highest logit\n",
    "        candidates = i.tolist()\n",
    "        decision = candidates.index(max(candidates))\n",
    "        yhats.append(decision)\n",
    "    \n",
    "    y = []\n",
    "    for text, label in val_dataset.unbatch():   \n",
    "      y.append(label.numpy())\n",
    "    \n",
    "    val_loss.append(loss)\n",
    "    val_acc.append(accuracy_score(y, yhats))\n",
    "    val_prec.append(precision_score(y, yhats))\n",
    "    val_rec.append(recall_score(y, yhats))\n",
    "    val_f1.append(f1_score(y, yhats))\n",
    "    val_f1_micro.append(f1_score(y, yhats, average='micro'))\n",
    "    val_f1_wmacro.append(f1_score(y, yhats, average='weighted'))\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    k += 1\n",
    "\n",
    "  return val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCWs4EWjy4Kp"
   },
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 643764,
     "status": "ok",
     "timestamp": 1620810209794,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "AV-PUSinUJnF",
    "outputId": "04cccd2e-997d-402e-83dc-537d3fcde5e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Start fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fcff315bd00>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fcff315bd00>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fd00ea07d40> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function wrap at 0x7fd00ea07d40> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6949WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - 81s 827ms/step - loss: 0.6938 - val_loss: 0.6230\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 31s 785ms/step - loss: 0.5671 - val_loss: 0.5686\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 31s 798ms/step - loss: 0.3779 - val_loss: 0.6115\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.5686\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6924WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - 47s 850ms/step - loss: 0.6913 - val_loss: 0.6510\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 31s 802ms/step - loss: 0.4693 - val_loss: 0.5219\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 30s 782ms/step - loss: 0.1939 - val_loss: 0.6911\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.5219\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6910WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - 49s 872ms/step - loss: 0.6901 - val_loss: 0.5286\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 32s 812ms/step - loss: 0.4648 - val_loss: 0.4567\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 31s 797ms/step - loss: 0.2261 - val_loss: 0.5923\n",
      "10/10 [==============================] - 3s 250ms/step - loss: 0.4567\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7022WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - 48s 854ms/step - loss: 0.7011 - val_loss: 0.5454\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 31s 796ms/step - loss: 0.4544 - val_loss: 0.5303\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 30s 781ms/step - loss: 0.1546 - val_loss: 0.6619\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.5303\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6666WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - 49s 882ms/step - loss: 0.6654 - val_loss: 0.5702\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 32s 818ms/step - loss: 0.4583 - val_loss: 0.4501\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 31s 803ms/step - loss: 0.1595 - val_loss: 0.5353\n",
      "10/10 [==============================] - 3s 251ms/step - loss: 0.4501\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "5-Fold CV Loss: 0.5055139303207398\n",
      "5-Fold CV Accuracy: 0.7649161518093557\n",
      "5-Fold CV Precision: 0.7723268878256538\n",
      "5-Fold CV Recall: 0.7543624161073825\n",
      "5-Fold CV F1 Score: 0.7516630925882166\n",
      "5-Fold CV Micro F1 Score: 0.7649161518093556\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7618697657898658\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# without distant signal pretraining\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='bert', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)\n",
    "\n",
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4OJmwP2ziMa"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# without distant signal pretraining\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='bert', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1062081,
     "status": "ok",
     "timestamp": 1620811281215,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "KI34Fj7zzAIh",
    "outputId": "71c4ed35-69a9-40d0-ca5e-97e028858ead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BERT on SG2\n",
      "5-Fold CV Loss: 0.4575493991374969\n",
      "5-Fold CV Accuracy: 0.7892706074255316\n",
      "5-Fold CV Precision: 0.7796414062302606\n",
      "5-Fold CV Recall: 0.8049723756906078\n",
      "5-Fold CV F1 Score: 0.7900329021285127\n",
      "5-Fold CV Micro F1 Score: 0.7892706074255315\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7886159511454031\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for BERT on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9t6QsLC5Oou"
   },
   "source": [
    "### BERT + distant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6042,
     "status": "ok",
     "timestamp": 1620811602006,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "tufL8EEl5NvY",
    "outputId": "0735c4a6-55e3-47ae-d28f-082baa1680f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load model layer weights from pretraining on distant dataset \n",
    "# compile model\n",
    "#transfer_model = TFRobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "transfer_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "transfer_model.compile(optimizer=optimizer, loss=transfer_model.compute_loss) \n",
    "\n",
    "transfer_model.load_weights('./checkpoints/bert_final_checkpoint_news_headlines_USA')\n",
    "trained_model_layer = transfer_model.get_layer(index=0).get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qp6TOmLP42nZ"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# with distant signal pretraining\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='bert', \n",
    "                                                                                            freeze_encoder=False, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 778,
     "status": "ok",
     "timestamp": 1620812125259,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "JGq54KK_5u1I",
    "outputId": "57b86c26-6288-4496-b3fd-8e5a93dde077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BERT + distant on SG1\n",
      "5-Fold CV Loss: 0.4784796714782715\n",
      "5-Fold CV Accuracy: 0.7791283150506451\n",
      "5-Fold CV Precision: 0.782222153066104\n",
      "5-Fold CV Recall: 0.7624161073825504\n",
      "5-Fold CV F1 Score: 0.7690257043162897\n",
      "5-Fold CV Micro F1 Score: 0.7791283150506451\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7782424758051683\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for BERT + distant on SG1')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ss4XWht750Ff"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# with distant signal pretraining\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='bert', \n",
    "                                                                                            freeze_encoder=False, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 994709,
     "status": "ok",
     "timestamp": 1620813141542,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "QmIN7OV155p3",
    "outputId": "d75bfae9-9499-4581-9b8a-445abf7d9d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for BERT + distant on SG2\n",
      "5-Fold CV Loss: 0.45280778408050537\n",
      "5-Fold CV Accuracy: 0.8047893380785556\n",
      "5-Fold CV Precision: 0.8010278449136129\n",
      "5-Fold CV Recall: 0.8082872928176796\n",
      "5-Fold CV F1 Score: 0.8027645188619399\n",
      "5-Fold CV Micro F1 Score: 0.8047893380785558\n",
      "5-Fold CV Weighted Macro F1 Score: 0.8043577261879854\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for BERT + distant on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCW0oaxBzonB"
   },
   "source": [
    "### DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqw59Djszq2X"
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='distilbert', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1620811585894,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "-j4gNOr9z9Tk",
    "outputId": "d7d77ed0-0180-4be2-a09f-2c6370a0ac51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for DistilBERT on SG1\n",
      "5-Fold CV Loss: 0.5034848332405091\n",
      "5-Fold CV Accuracy: 0.7603517841381919\n",
      "5-Fold CV Precision: 0.7851353351520555\n",
      "5-Fold CV Recall: 0.7006711409395974\n",
      "5-Fold CV F1 Score: 0.736955546776338\n",
      "5-Fold CV Micro F1 Score: 0.7603517841381919\n",
      "5-Fold CV Weighted Macro F1 Score: 0.758224422060177\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for DistilBERT on SG1')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHqfzE-jz4lm"
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='distilbert', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 515463,
     "status": "ok",
     "timestamp": 1620813683857,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "9kt0gOdy0ALD",
    "outputId": "44839d74-8c34-4050-f15f-463c805d47f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for DistilBERT on SG2\n",
      "5-Fold CV Loss: 0.47459145188331603\n",
      "5-Fold CV Accuracy: 0.7783788392741292\n",
      "5-Fold CV Precision: 0.7914496007137517\n",
      "5-Fold CV Recall: 0.756353591160221\n",
      "5-Fold CV F1 Score: 0.768966991077014\n",
      "5-Fold CV Micro F1 Score: 0.7783788392741293\n",
      "5-Fold CV Weighted Macro F1 Score: 0.777102422253571\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for DistilBERT on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRTchi-m2hYh"
   },
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSUsyFiz2kTV"
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='roberta', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1620814269788,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "bmGQKU3h22jD",
    "outputId": "0bfd3c9d-54cc-40d4-a96c-d7efe1d297d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RoBERTa on SG1\n",
      "5-Fold CV Loss: 0.4697426736354828\n",
      "5-Fold CV Accuracy: 0.7784621527339974\n",
      "5-Fold CV Precision: 0.7825771209819836\n",
      "5-Fold CV Recall: 0.7758389261744967\n",
      "5-Fold CV F1 Score: 0.7715627724463581\n",
      "5-Fold CV Micro F1 Score: 0.7784621527339974\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7752193988259601\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for RoBERTa on SG1')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajU2IyFX2563"
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='roberta', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1620816413940,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "oJCJpFDy3AY5",
    "outputId": "70c6f7bd-59cb-474e-eee0-2c8f8f9a0560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RoBERTa on SG2\n",
      "5-Fold CV Loss: 0.45095362067222594\n",
      "5-Fold CV Accuracy: 0.8007054811025227\n",
      "5-Fold CV Precision: 0.7834945430249991\n",
      "5-Fold CV Recall: 0.8337016574585636\n",
      "5-Fold CV F1 Score: 0.8042913565026074\n",
      "5-Fold CV Micro F1 Score: 0.8007054811025227\n",
      "5-Fold CV Weighted Macro F1 Score: 0.799347878132545\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for RoBERTa on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOMwgdo9H2Ax"
   },
   "source": [
    "### RoBERTa + distant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33368,
     "status": "ok",
     "timestamp": 1620816448547,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "xgmGx_olHxw0",
    "outputId": "5c714802-dcdf-4e50-e685-b6c57215a78e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load model layer weights from pretraining on distant dataset \n",
    "# compile model\n",
    "transfer_model = TFRobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "transfer_model.compile(optimizer=optimizer, loss=transfer_model.compute_loss) \n",
    "\n",
    "transfer_model.load_weights('./checkpoints/roberta_final_checkpoint_news_headlines_USA')\n",
    "trained_model_layer = transfer_model.get_layer(index=0).get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pevLAcJCH_qD"
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='roberta', \n",
    "                                                                                            freeze_encoder=False, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 634561,
     "status": "ok",
     "timestamp": 1620817049768,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "Vs_brFmCIDPk",
    "outputId": "6dab2001-bc9d-424e-db19-ce41d95fe2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RoBERTa + distant on SG1\n",
      "5-Fold CV Loss: 0.44771517515182496\n",
      "5-Fold CV Accuracy: 0.7985668053629219\n",
      "5-Fold CV Precision: 0.7758359785184737\n",
      "5-Fold CV Recall: 0.832214765100671\n",
      "5-Fold CV F1 Score: 0.7999256262460596\n",
      "5-Fold CV Micro F1 Score: 0.7985668053629217\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7977665899984501\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for RoBERTa + distant on SG1')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1105085,
     "status": "ok",
     "timestamp": 1620818309017,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "IQ_FG4ysIAVi",
    "outputId": "0ad63d17-e8b9-4dc4-997c-15bcb245017c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Start fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5349WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - 97s 877ms/step - loss: 0.5345 - val_loss: 0.4133\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 78s 845ms/step - loss: 0.3409 - val_loss: 0.4796\n",
      "23/23 [==============================] - 5s 234ms/step - loss: 0.4133\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5679WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - 95s 874ms/step - loss: 0.5673 - val_loss: 0.4084\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 77s 841ms/step - loss: 0.3456 - val_loss: 0.4032\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 77s 841ms/step - loss: 0.2353 - val_loss: 0.5046\n",
      "23/23 [==============================] - 5s 215ms/step - loss: 0.4032\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5390WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - 96s 875ms/step - loss: 0.5386 - val_loss: 0.4585\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 77s 841ms/step - loss: 0.3569 - val_loss: 0.4767\n",
      "23/23 [==============================] - 5s 222ms/step - loss: 0.4585\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5427WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - 97s 882ms/step - loss: 0.5422 - val_loss: 0.4699\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 78s 845ms/step - loss: 0.3178 - val_loss: 0.4695\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 78s 844ms/step - loss: 0.2017 - val_loss: 0.5180\n",
      "23/23 [==============================] - 5s 233ms/step - loss: 0.4695\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5487WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "92/92 [==============================] - 89s 800ms/step - loss: 0.5482 - val_loss: 0.4198\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 70s 765ms/step - loss: 0.3592 - val_loss: 0.4554\n",
      "23/23 [==============================] - 6s 263ms/step - loss: 0.4198\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='roberta', \n",
    "                                                                                            freeze_encoder=False, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1103746,
     "status": "ok",
     "timestamp": 1620818309018,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "hqneQf2yIFmR",
    "outputId": "45fa5790-08c0-404c-9a6f-18a8bd85a602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RoBERTa + distant on SG2\n",
      "5-Fold CV Loss: 0.4328740358352661\n",
      "5-Fold CV Accuracy: 0.8007017738975699\n",
      "5-Fold CV Precision: 0.8479610779798031\n",
      "5-Fold CV Recall: 0.72707182320442\n",
      "5-Fold CV F1 Score: 0.7811997062364262\n",
      "5-Fold CV Micro F1 Score: 0.8007017738975699\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7990983671260622\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for RoBERTa + distant on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVwXBK-03SbE"
   },
   "source": [
    "### ELECTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XW7tbu6f3RqZ"
   },
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='electra', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1620818807674,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "TZLodIFy3o7l",
    "outputId": "a3d3f877-6160-4bb6-b6ae-d670072d0466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ELECTRA on SG1\n",
      "5-Fold CV Loss: 0.5440825581550598\n",
      "5-Fold CV Accuracy: 0.7448009918883706\n",
      "5-Fold CV Precision: 0.7614052309887166\n",
      "5-Fold CV Recall: 0.6966442953020134\n",
      "5-Fold CV F1 Score: 0.7211321040106528\n",
      "5-Fold CV Micro F1 Score: 0.7448009918883706\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7422210680339413\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for ELECTRA on SG1')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ds_QU-K43jgD"
   },
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='electra', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1620819133471,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "9CvLJFmM3rgB",
    "outputId": "bdb23da3-a285-4ea4-c144-dca0f17a59f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ELECTRA on SG2\n",
      "5-Fold CV Loss: 0.5140148580074311\n",
      "5-Fold CV Accuracy: 0.7625935605849968\n",
      "5-Fold CV Precision: 0.809470758694404\n",
      "5-Fold CV Recall: 0.6861878453038674\n",
      "5-Fold CV F1 Score: 0.7379172614803242\n",
      "5-Fold CV Micro F1 Score: 0.7625935605849969\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7597981280791523\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for ELECTRA on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhsBtQ_S3tcC"
   },
   "source": [
    "### XLNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49GtDW9A3u79"
   },
   "outputs": [],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg1, model_name='xlnet', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1034722,
     "status": "ok",
     "timestamp": 1620820431129,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "L18ta1df3_8R",
    "outputId": "099993a2-69c6-42a0-9e40-4008d59f2d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for XLNET on SG1\n",
      "5-Fold CV Loss: 0.5028677642345428\n",
      "5-Fold CV Accuracy: 0.7616525868953054\n",
      "5-Fold CV Precision: 0.7908365542157949\n",
      "5-Fold CV Recall: 0.6939597315436242\n",
      "5-Fold CV F1 Score: 0.7374808169992624\n",
      "5-Fold CV Micro F1 Score: 0.7616525868953054\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7600315195814671\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for XLNET on SG1')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1747441,
     "status": "ok",
     "timestamp": 1620822883385,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "OR8tCwlo37bb",
    "outputId": "0a85a6b1-c2ad-430b-a807-20bc9278042a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Start fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5651WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "92/92 [==============================] - 120s 1s/step - loss: 0.5646 - val_loss: 0.4400\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 102s 1s/step - loss: 0.3625 - val_loss: 0.5188\n",
      "23/23 [==============================] - 6s 274ms/step - loss: 0.4400\n",
      "### Start fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5888WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "92/92 [==============================] - 119s 1s/step - loss: 0.5882 - val_loss: 0.4410\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 103s 1s/step - loss: 0.3883 - val_loss: 0.4071\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 103s 1s/step - loss: 0.2283 - val_loss: 0.4403\n",
      "23/23 [==============================] - 7s 306ms/step - loss: 0.4071\n",
      "### Start fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.6144WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "92/92 [==============================] - 120s 1s/step - loss: 0.6138 - val_loss: 0.4555\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 102s 1s/step - loss: 0.4001 - val_loss: 0.4433\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 102s 1s/step - loss: 0.2120 - val_loss: 0.4951\n",
      "23/23 [==============================] - 6s 283ms/step - loss: 0.4433\n",
      "### Start fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5820WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "92/92 [==============================] - 121s 1s/step - loss: 0.5813 - val_loss: 0.4738\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 103s 1s/step - loss: 0.3515 - val_loss: 0.5895\n",
      "23/23 [==============================] - 7s 324ms/step - loss: 0.4738\n",
      "### Start fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0'] when minimizing the loss.\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5740WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "92/92 [==============================] - 113s 1s/step - loss: 0.5735 - val_loss: 0.4463\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 96s 1s/step - loss: 0.3819 - val_loss: 0.4720\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.4463\n"
     ]
    }
   ],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_sg2, model_name='xlnet', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1025,
     "status": "ok",
     "timestamp": 1620822884448,
     "user": {
      "displayName": "Manuel Plank",
      "photoUrl": "",
      "userId": "17725031238816109220"
     },
     "user_tz": -120
    },
    "id": "jgr6g6HG4FVX",
    "outputId": "07a0ed39-f26b-4c99-d32b-46a27679d9f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for XLNET on SG2\n",
      "5-Fold CV Loss: 0.4420862317085266\n",
      "5-Fold CV Accuracy: 0.7974357263341304\n",
      "5-Fold CV Precision: 0.8162492174406484\n",
      "5-Fold CV Recall: 0.76353591160221\n",
      "5-Fold CV F1 Score: 0.7870615420108473\n",
      "5-Fold CV Micro F1 Score: 0.7974357263341304\n",
      "5-Fold CV Weighted Macro F1 Score: 0.7967053530729449\n"
     ]
    }
   ],
   "source": [
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('Results for XLNET on SG2')\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "CycNYDUX--EY",
    "9xfkXD3PYX8R",
    "79o0mpSaYX8Z",
    "xwsmR_nqYX8d"
   ],
   "name": "classification_emnlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "041ab695abc740b0b23b80b6d47354e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "05de6e41179248a1abeaff4c3d248398": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1087a4b82b424e76a9869590d3944af4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ff2fa37c94e412c836224c447fe6bf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9f8a2524f8a4c17a197a8078e31ce49",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d632b1a86e4e4492b99cf549e3f021ec",
      "value": 231508
     }
    },
    "22dde6c419744d6aa222309d784fd108": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26ae333f14b142868be336015e64abb2",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae726ea844c7435c9c9db6ff31848be3",
      "value": 231508
     }
    },
    "23855aa0fb6244d98d5044da23814836": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3245d896e7c4f158ab0b4da76ea93a4",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c2f751936f5746ae939295cb88367292",
      "value": 28
     }
    },
    "2655bffd46c64f1f82b98d6bce0b1e73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26ae333f14b142868be336015e64abb2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26c6e7e422e44eefa842bfaf9e33ad03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1087a4b82b424e76a9869590d3944af4",
      "placeholder": "​",
      "style": "IPY_MODEL_05de6e41179248a1abeaff4c3d248398",
      "value": " 363M/363M [00:06&lt;00:00, 56.0MB/s]"
     }
    },
    "29349e0af5804f088ee778f08d7b482a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "296a2491f36e44b0bfbda55362e69874": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9478c98deb464cbf87aefa08ad3cf4ea",
       "IPY_MODEL_fe5bf9b7cbc84353bd8091c3f23acf18"
      ],
      "layout": "IPY_MODEL_a228898978784790a1f0f41a2da5881c"
     }
    },
    "2c58f409b9e64b3ba9a6bca68cd193c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38ce582a81e549f3bf356693dbe2d558",
      "placeholder": "​",
      "style": "IPY_MODEL_c850cf5b66ee45a698b5a32eddff5c30",
      "value": " 442/442 [00:00&lt;00:00, 2.36kB/s]"
     }
    },
    "311c872733504f0a804f73f6f49a9ea4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "333fd819aafa426892022abb6a72552d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3372ecb786754704b2321f47ad4263d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3395978288894e6cbcad914695ead617": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38ce582a81e549f3bf356693dbe2d558": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b6867a6625c4f9890040cabfc57f3a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3dbd5593c44f408d96fb8906984045d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_22dde6c419744d6aa222309d784fd108",
       "IPY_MODEL_7260901878224b42aed032408c11be0c"
      ],
      "layout": "IPY_MODEL_3372ecb786754704b2321f47ad4263d3"
     }
    },
    "3dde9e7cce1d4c4ab58af138ce8015fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "46ce1f04fe3140f5962fa05c7cc71f28": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4cd630bd8b0c4cdeb8ca7cf567939c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b09076acca74b3e938312ad24850080",
       "IPY_MODEL_2c58f409b9e64b3ba9a6bca68cd193c4"
      ],
      "layout": "IPY_MODEL_2655bffd46c64f1f82b98d6bce0b1e73"
     }
    },
    "52c26cbdfa3a41b3979d37f8d504efd6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "553ed5546d45464db8cfa1c67fee040a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_311c872733504f0a804f73f6f49a9ea4",
      "placeholder": "​",
      "style": "IPY_MODEL_d499b2c8dc88467ca3fb077c364163cf",
      "value": " 466k/466k [00:00&lt;00:00, 1.35MB/s]"
     }
    },
    "5c3ba5b9183d4fe697e84337907920b8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62c8991c62e346dca0041cda351edb97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6b09076acca74b3e938312ad24850080": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bc7e65f21f54fb6acc90b64925365a3",
      "max": 442,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_333fd819aafa426892022abb6a72552d",
      "value": 442
     }
    },
    "6bc7e65f21f54fb6acc90b64925365a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c52cabb9ece48b58ceb073437fdc439": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_23855aa0fb6244d98d5044da23814836",
       "IPY_MODEL_dbeee3b64dc94284a4775f2a0cb4dfa4"
      ],
      "layout": "IPY_MODEL_e46833e1a05e48ae8b1c6087bb00ee0f"
     }
    },
    "7260901878224b42aed032408c11be0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c22c14995e3747889c496c46429d8bbd",
      "placeholder": "​",
      "style": "IPY_MODEL_cac0198656f247899aca5086c2b408be",
      "value": " 232k/232k [00:00&lt;00:00, 938kB/s]"
     }
    },
    "79df1255843b48aabe25b5ff547b5783": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bafa4dd539714c5b8100494b9b5bf071",
       "IPY_MODEL_553ed5546d45464db8cfa1c67fee040a"
      ],
      "layout": "IPY_MODEL_d19186b71be744899b772642934539e1"
     }
    },
    "7fa44254f5b6467791a4b508504f1b40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81dd8afd3da148c084f84b3d34329812": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ff2fa37c94e412c836224c447fe6bf7",
       "IPY_MODEL_bfaab7f593fb4bd088a64592a8b53663"
      ],
      "layout": "IPY_MODEL_fc5f1f66fc694d668251a47e1e379f8b"
     }
    },
    "81e01b1fc1824ae6a795c324f05d43f7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b77d22d29d34e44994386d132db4613": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ef26ad478f040b1808e510e1dd5330d",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3dde9e7cce1d4c4ab58af138ce8015fe",
      "value": 466062
     }
    },
    "8ef26ad478f040b1808e510e1dd5330d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9478c98deb464cbf87aefa08ad3cf4ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29349e0af5804f088ee778f08d7b482a",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62c8991c62e346dca0041cda351edb97",
      "value": 28
     }
    },
    "a0cc5026b48c406ca66ea232842b4649": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a228898978784790a1f0f41a2da5881c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae726ea844c7435c9c9db6ff31848be3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b1f3438d4f8449d8b8c07a8e5197aed5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bafa4dd539714c5b8100494b9b5bf071": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81e01b1fc1824ae6a795c324f05d43f7",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca24677e1d2f4431a14c60ba268bf0fb",
      "value": 466062
     }
    },
    "bfaab7f593fb4bd088a64592a8b53663": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c3ba5b9183d4fe697e84337907920b8",
      "placeholder": "​",
      "style": "IPY_MODEL_46ce1f04fe3140f5962fa05c7cc71f28",
      "value": " 232k/232k [00:01&lt;00:00, 121kB/s]"
     }
    },
    "c22c14995e3747889c496c46429d8bbd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2f751936f5746ae939295cb88367292": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c4b80324c25c4449a716802a2e509d57": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa846344c2e04735aaae4542988becb0",
       "IPY_MODEL_26c6e7e422e44eefa842bfaf9e33ad03"
      ],
      "layout": "IPY_MODEL_3395978288894e6cbcad914695ead617"
     }
    },
    "c850cf5b66ee45a698b5a32eddff5c30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9f8a2524f8a4c17a197a8078e31ce49": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca24677e1d2f4431a14c60ba268bf0fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cac0198656f247899aca5086c2b408be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "caceb8515d614c109d4f74848530aa51": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d19186b71be744899b772642934539e1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3245d896e7c4f158ab0b4da76ea93a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d366be34c995437d9d2eae8b5fb311c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d499b2c8dc88467ca3fb077c364163cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4bd173bc89b41ccaac8f8e2d2ee9a89": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d632b1a86e4e4492b99cf549e3f021ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dbeee3b64dc94284a4775f2a0cb4dfa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_caceb8515d614c109d4f74848530aa51",
      "placeholder": "​",
      "style": "IPY_MODEL_3b6867a6625c4f9890040cabfc57f3a7",
      "value": " 28.0/28.0 [00:00&lt;00:00, 57.4B/s]"
     }
    },
    "e46833e1a05e48ae8b1c6087bb00ee0f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9216fe34bc8441ab10e8737a7fa8c70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0cc5026b48c406ca66ea232842b4649",
      "placeholder": "​",
      "style": "IPY_MODEL_d4bd173bc89b41ccaac8f8e2d2ee9a89",
      "value": " 466k/466k [00:00&lt;00:00, 3.20MB/s]"
     }
    },
    "fa846344c2e04735aaae4542988becb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52c26cbdfa3a41b3979d37f8d504efd6",
      "max": 363423424,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_041ab695abc740b0b23b80b6d47354e8",
      "value": 363423424
     }
    },
    "fc5f1f66fc694d668251a47e1e379f8b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc6e2911e71c44798ed76cdcec7ad099": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b77d22d29d34e44994386d132db4613",
       "IPY_MODEL_f9216fe34bc8441ab10e8737a7fa8c70"
      ],
      "layout": "IPY_MODEL_d366be34c995437d9d2eae8b5fb311c0"
     }
    },
    "fe5bf9b7cbc84353bd8091c3f23acf18": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1f3438d4f8449d8b8c07a8e5197aed5",
      "placeholder": "​",
      "style": "IPY_MODEL_7fa44254f5b6467791a4b508504f1b40",
      "value": " 28.0/28.0 [00:16&lt;00:00, 1.69B/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
